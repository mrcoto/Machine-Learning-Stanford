# Machine Learning - Stanford

Respuestas propias para los ejercicios semanales del curso.

Más que nada un respaldo de funciones útiles que se podrán usar en un futuro al realizar
prototipos de ML.

## Semana 2

La semana 2 contiene ejercicios de regresión lineal (univariable y multivariable).
- Gradiente de Descenso (Gradient Descent)
- Escalamiento (Feature Normalization)
- Ecuación Normal (Normal Equation)

## Semana 3

La semana 3 contiene ejercicios de clasificación (regresión logística) y de regularización.
- Clasificación (Regresión Logística)
- Clasificación multi clase (one-vs-all)
- Optimización avanzada (Gradiente conjugada, BFGS, L-FBGS). Se vió como "fminunc" en Octave
- Problemas de Sobreajuste (Overfitting) o de bajo ajuste (Underfitting)
- Regularización (Para regresión líneal y clasificación)

## Semana 4

La semana 4 contiene ejercicios de clasificación multi clase (regresión logística) para identificar dígitos (0, 1, .., 9)
de una imagen.
- Clasificación multi clase (one-vs-all)
- Forward Propagation (FP) para Precedir dígitos de imagen de una Red Neuronal ya entrenada

## Semana 5

La semana 5 contiene ejercicios de Feedforward propagation (FP) y Backpropagation (BP), ambos con términos de regularización.
Se utilizaron para encontrar los peros que identifican los dígitos del 0 al 9 (de la Semana 4).
- Feedforward propagation (FP) + Término de regularización
- Backpropagation (Obtención de Gradiente)
- Gradient Checking (Ya estaba implementado, verifica que BP funciona correctamente)

## Semana 6

La semana 6 contiene ejercicios de Bias vs Varianza aplicado a una regresión lineal regularizada.
- Bias vs Varianza 
- Curva de aprendizaje

## Semana 7

La semana 7 contiene ejercicios de Super Vector Machine (SVM) para clasificar un email como spam/no spam
- SVM con Kernel Gaussiano